{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HuggingFace 医学图像分割 - 测试Notebook\n",
        "\n",
        "本notebook用于测试HuggingFace预训练模型的基本功能，不进行训练。\n",
        "\n",
        "## 功能：\n",
        "1. 数据加载和预处理测试\n",
        "2. 模型创建和前向传播测试\n",
        "3. 数据可视化\n",
        "4. 基本预测测试\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 安装依赖和挂载Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 挂载Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 安装必要的包\n",
        "%pip install segmentation-models-pytorch -q\n",
        "%pip install nibabel -q\n",
        "%pip install albumentations -q\n",
        "%pip install matplotlib -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 导入必要的库\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import nibabel as nib\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 设置设备\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"使用设备: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"显存: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 配置参数\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 数据路径\n",
        "DRIVE_DATA_PATH = \"/content/drive/MyDrive/data-brain-2024\"\n",
        "\n",
        "# 测试参数\n",
        "IMG_SIZE = 256\n",
        "NUM_CLASSES = 4\n",
        "SLICE_START = 22\n",
        "NUM_SLICES = 100\n",
        "\n",
        "# 模型参数\n",
        "MODEL_TYPE = 'unet'\n",
        "PRETRAINED_ENCODER = 'resnet34'\n",
        "\n",
        "print(f\"图像尺寸: {IMG_SIZE}x{IMG_SIZE}\")\n",
        "print(f\"模型类型: {MODEL_TYPE}\")\n",
        "print(f\"预训练编码器: {PRETRAINED_ENCODER}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 数据加载函数\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_patient_groups(data_path):\n",
        "    \"\"\"获取所有患者的数据分组\"\"\"\n",
        "    all_files = glob.glob(os.path.join(data_path, \"*.nii\"))\n",
        "    patient_groups = defaultdict(lambda: defaultdict(dict))\n",
        "\n",
        "    for file_path in all_files:\n",
        "        filename = os.path.basename(file_path)\n",
        "        match = re.match(r'BraTS-GLI-(\\d+)-(\\d+)-(t1n|t2f|t2w|t1c|seg)\\.nii', filename)\n",
        "        if match:\n",
        "            patient_id = match.group(1)\n",
        "            sequence_id = match.group(2)\n",
        "            modality = match.group(3)\n",
        "            patient_groups[patient_id][sequence_id][modality] = file_path\n",
        "\n",
        "    complete_patients = {}\n",
        "    for patient_id, sequences in patient_groups.items():\n",
        "        for seq_id, modalities in sequences.items():\n",
        "            if 't2f' in modalities and 't1c' in modalities and 'seg' in modalities:\n",
        "                if patient_id not in complete_patients:\n",
        "                    complete_patients[patient_id] = {}\n",
        "                complete_patients[patient_id][seq_id] = modalities\n",
        "\n",
        "    return complete_patients\n",
        "\n",
        "def load_nifti_volume(file_path):\n",
        "    \"\"\"加载NIfTI文件并返回numpy数组\"\"\"\n",
        "    nii = nib.load(file_path)\n",
        "    data = nii.get_fdata()\n",
        "    return data\n",
        "\n",
        "def extract_slices_from_volume(volume, start_idx=22, num_slices=100):\n",
        "    \"\"\"从3D体积中提取2D切片（沿z轴）\"\"\"\n",
        "    depth = volume.shape[2]\n",
        "    end_idx = min(start_idx + num_slices, depth)\n",
        "    slices = volume[:, :, start_idx:end_idx]\n",
        "    return slices\n",
        "\n",
        "def normalize_slice(slice_data):\n",
        "    \"\"\"归一化单个切片\"\"\"\n",
        "    slice_data = slice_data.astype(np.float32)\n",
        "    max_val = np.max(slice_data)\n",
        "    if max_val > 0:\n",
        "        slice_data = slice_data / max_val\n",
        "    return slice_data\n",
        "\n",
        "def remap_labels(label_slice):\n",
        "    \"\"\"将标签值4映射到3\"\"\"\n",
        "    label_slice = label_slice.astype(np.int64)\n",
        "    label_slice[label_slice == 4] = 3\n",
        "    return label_slice\n",
        "\n",
        "# 获取所有患者数据\n",
        "all_patient_groups = get_patient_groups(DRIVE_DATA_PATH)\n",
        "patient_ids = list(all_patient_groups.keys())\n",
        "\n",
        "print(f\"找到 {len(patient_ids)} 个患者\")\n",
        "print(f\"前5个患者ID: {patient_ids[:5]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 加载并可视化一个样本\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 选择一个患者进行测试\n",
        "test_patient_id = patient_ids[0]\n",
        "test_seq_id = list(all_patient_groups[test_patient_id].keys())[0]\n",
        "test_modalities = all_patient_groups[test_patient_id][test_seq_id]\n",
        "\n",
        "print(f\"测试患者ID: {test_patient_id}\")\n",
        "print(f\"测试序列ID: {test_seq_id}\")\n",
        "print(f\"模态文件:\")\n",
        "for mod, path in test_modalities.items():\n",
        "    print(f\"  {mod}: {path}\")\n",
        "\n",
        "# 加载3D体积\n",
        "t2f_volume = load_nifti_volume(test_modalities['t2f'])\n",
        "t1c_volume = load_nifti_volume(test_modalities['t1c'])\n",
        "seg_volume = load_nifti_volume(test_modalities['seg'])\n",
        "\n",
        "print(f\"\\n体积形状:\")\n",
        "print(f\"  FLAIR: {t2f_volume.shape}\")\n",
        "print(f\"  T1CE: {t1c_volume.shape}\")\n",
        "print(f\"  标签: {seg_volume.shape}\")\n",
        "\n",
        "# 提取一个切片\n",
        "slice_idx = 50  # 选择中间的一个切片\n",
        "t2f_slice = t2f_volume[:, :, slice_idx]\n",
        "t1c_slice = t1c_volume[:, :, slice_idx]\n",
        "seg_slice = seg_volume[:, :, slice_idx]\n",
        "\n",
        "# 归一化\n",
        "t2f_slice_norm = normalize_slice(t2f_slice)\n",
        "t1c_slice_norm = normalize_slice(t1c_slice)\n",
        "seg_slice_remap = remap_labels(seg_slice)\n",
        "\n",
        "print(f\"\\n切片形状:\")\n",
        "print(f\"  FLAIR: {t2f_slice_norm.shape}\")\n",
        "print(f\"  T1CE: {t1c_slice_norm.shape}\")\n",
        "print(f\"  标签: {seg_slice_remap.shape}\")\n",
        "print(f\"  标签值范围: {seg_slice_remap.min()} - {seg_slice_remap.max()}\")\n",
        "print(f\"  标签值分布: {np.bincount(seg_slice_remap.flatten())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 可视化原始切片\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axes[0].imshow(t2f_slice_norm, cmap='gray')\n",
        "axes[0].set_title(f'FLAIR (切片 {slice_idx})')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(t1c_slice_norm, cmap='gray')\n",
        "axes[1].set_title(f'T1CE (切片 {slice_idx})')\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(seg_slice_remap, cmap='tab10', vmin=0, vmax=3)\n",
        "axes[2].set_title(f'标签 (切片 {slice_idx})')\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 测试数据预处理（Albumentations）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# 创建数据增强管道\n",
        "transform = A.Compose([\n",
        "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "    A.Normalize(mean=[0.5, 0.5], std=[0.5, 0.5]),  # 归一化到[-1, 1]\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "label_transform = A.Compose([\n",
        "    A.Resize(IMG_SIZE, IMG_SIZE, interpolation=0),  # 最近邻插值\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# 准备2通道图像\n",
        "image_2ch = np.stack([t2f_slice_norm, t1c_slice_norm], axis=0)  # (2, H, W)\n",
        "image_2ch = np.transpose(image_2ch, (1, 2, 0))  # (H, W, 2)\n",
        "\n",
        "# 应用变换\n",
        "transformed = transform(image=image_2ch)\n",
        "image_tensor = transformed['image']  # (2, H, W)\n",
        "\n",
        "label_transformed = label_transform(image=seg_slice_remap)\n",
        "label_tensor = label_transformed['image'].squeeze(0).long()  # (H, W)\n",
        "\n",
        "print(f\"预处理后的形状:\")\n",
        "print(f\"  图像: {image_tensor.shape}\")\n",
        "print(f\"  标签: {label_tensor.shape}\")\n",
        "print(f\"  图像值范围: [{image_tensor.min():.3f}, {image_tensor.max():.3f}]\")\n",
        "print(f\"  标签值范围: {label_tensor.min()} - {label_tensor.max()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 创建并测试模型\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# 创建UNet模型（使用预训练编码器）\n",
        "def create_model(model_type='unet', encoder_name='resnet34', num_classes=4, in_channels=2):\n",
        "    \"\"\"创建分割模型\"\"\"\n",
        "    if model_type == 'unet':\n",
        "        model = smp.Unet(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights='imagenet',  # 使用ImageNet预训练权重\n",
        "            in_channels=in_channels,\n",
        "            classes=num_classes,\n",
        "            activation=None,  # 使用logits\n",
        "        )\n",
        "    elif model_type == 'fpn':\n",
        "        model = smp.FPN(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights='imagenet',\n",
        "            in_channels=in_channels,\n",
        "            classes=num_classes,\n",
        "            activation=None,\n",
        "        )\n",
        "    elif model_type == 'linknet':\n",
        "        model = smp.Linknet(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights='imagenet',\n",
        "            in_channels=in_channels,\n",
        "            classes=num_classes,\n",
        "            activation=None,\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"不支持的模型类型: {model_type}\")\n",
        "    \n",
        "    return model\n",
        "\n",
        "# 创建模型\n",
        "print(\"正在创建模型...\")\n",
        "model = create_model(\n",
        "    model_type=MODEL_TYPE,\n",
        "    encoder_name=PRETRAINED_ENCODER,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    in_channels=2  # FLAIR + T1CE\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 打印模型信息\n",
        "print(f\"\\n模型信息:\")\n",
        "print(f\"  模型类型: {MODEL_TYPE}\")\n",
        "print(f\"  编码器: {PRETRAINED_ENCODER}\")\n",
        "print(f\"  输入通道: 2 (FLAIR + T1CE)\")\n",
        "print(f\"  输出类别: {NUM_CLASSES}\")\n",
        "\n",
        "# 计算参数量\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\n参数量:\")\n",
        "print(f\"  总参数量: {total_params / 1e6:.2f}M\")\n",
        "print(f\"  可训练参数量: {trainable_params / 1e6:.2f}M\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 测试前向传播\n",
        "print(\"\\n测试前向传播...\")\n",
        "with torch.no_grad():\n",
        "    # 添加batch维度\n",
        "    test_input = image_tensor.unsqueeze(0).to(device)  # (1, 2, H, W)\n",
        "    print(f\"输入形状: {test_input.shape}\")\n",
        "    \n",
        "    # 前向传播\n",
        "    test_output = model(test_input)\n",
        "    print(f\"输出形状: {test_output.shape}\")\n",
        "    print(f\"期望输出形状: (1, {NUM_CLASSES}, {IMG_SIZE}, {IMG_SIZE})\")\n",
        "    \n",
        "    # 检查输出\n",
        "    print(f\"\\n输出统计:\")\n",
        "    print(f\"  值范围: [{test_output.min().item():.3f}, {test_output.max().item():.3f}]\")\n",
        "    print(f\"  均值: {test_output.mean().item():.3f}\")\n",
        "    print(f\"  标准差: {test_output.std().item():.3f}\")\n",
        "    \n",
        "    # 应用softmax获取概率\n",
        "    probs = torch.softmax(test_output, dim=1)\n",
        "    pred_classes = torch.argmax(probs, dim=1).squeeze(0)  # (H, W)\n",
        "    \n",
        "    print(f\"\\n预测结果:\")\n",
        "    print(f\"  预测类别形状: {pred_classes.shape}\")\n",
        "    print(f\"  预测类别值范围: {pred_classes.min().item()} - {pred_classes.max().item()}\")\n",
        "    print(f\"  预测类别分布: {torch.bincount(pred_classes.flatten())}\")\n",
        "    \n",
        "print(\"\\n✅ 模型前向传播测试成功！\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 可视化预测结果\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 可视化输入、真实标签和预测结果\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "# 第一行：输入图像\n",
        "axes[0, 0].imshow(image_tensor[0].cpu().numpy(), cmap='gray')\n",
        "axes[0, 0].set_title('FLAIR (预处理后)')\n",
        "axes[0, 0].axis('off')\n",
        "\n",
        "axes[0, 1].imshow(image_tensor[1].cpu().numpy(), cmap='gray')\n",
        "axes[0, 1].set_title('T1CE (预处理后)')\n",
        "axes[0, 1].axis('off')\n",
        "\n",
        "axes[0, 2].axis('off')  # 空白\n",
        "\n",
        "# 第二行：标签和预测\n",
        "axes[1, 0].imshow(label_tensor.cpu().numpy(), cmap='tab10', vmin=0, vmax=3)\n",
        "axes[1, 0].set_title('真实标签')\n",
        "axes[1, 0].axis('off')\n",
        "\n",
        "axes[1, 1].imshow(pred_classes.cpu().numpy(), cmap='tab10', vmin=0, vmax=3)\n",
        "axes[1, 1].set_title('预测结果（未训练模型）')\n",
        "axes[1, 1].axis('off')\n",
        "\n",
        "# 显示每个类别的概率图\n",
        "class_probs = probs.squeeze(0)  # (C, H, W)\n",
        "for c in range(1, NUM_CLASSES):  # 跳过背景\n",
        "    axes[1, 2].imshow(class_probs[c].cpu().numpy(), cmap='hot', vmin=0, vmax=1)\n",
        "    axes[1, 2].set_title(f'类别 {c} 概率图')\n",
        "    axes[1, 2].axis('off')\n",
        "    break  # 只显示第一个非背景类别\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n注意：这是未训练模型的预测结果，仅用于测试模型是否能正常运行。\")\n",
        "print(\"实际训练后，预测结果应该会更接近真实标签。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 测试损失函数\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 测试损失函数\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, num_classes=4, smooth=1e-6):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.smooth = smooth\n",
        "    \n",
        "    def forward(self, pred, target):\n",
        "        pred = torch.softmax(pred, dim=1)\n",
        "        target_one_hot = torch.zeros_like(pred)\n",
        "        target_one_hot.scatter_(1, target.unsqueeze(1), 1)\n",
        "        \n",
        "        dice_scores = []\n",
        "        for c in range(1, self.num_classes):  # 跳过背景\n",
        "            pred_c = pred[:, c]\n",
        "            target_c = target_one_hot[:, c]\n",
        "            intersection = (pred_c * target_c).sum()\n",
        "            union = pred_c.sum() + target_c.sum()\n",
        "            dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
        "            dice_scores.append(dice)\n",
        "        \n",
        "        dice_loss = 1.0 - torch.stack(dice_scores).mean()\n",
        "        return dice_loss\n",
        "\n",
        "# 测试损失计算\n",
        "dice_loss = DiceLoss(num_classes=NUM_CLASSES)\n",
        "ce_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# 准备输入\n",
        "test_output_batch = test_output  # (1, C, H, W)\n",
        "test_label_batch = label_tensor.unsqueeze(0).to(device)  # (1, H, W)\n",
        "\n",
        "# 计算损失\n",
        "dice = dice_loss(test_output_batch, test_label_batch)\n",
        "ce = ce_loss(test_output_batch, test_label_batch)\n",
        "combined = 0.5 * dice + 0.5 * ce\n",
        "\n",
        "print(\"损失函数测试:\")\n",
        "print(f\"  Dice Loss: {dice.item():.4f}\")\n",
        "print(f\"  CrossEntropy Loss: {ce.item():.4f}\")\n",
        "print(f\"  组合损失: {combined.item():.4f}\")\n",
        "\n",
        "print(\"\\n✅ 所有测试完成！模型和数据管道工作正常。\")\n",
        "print(\"可以开始训练了！\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
